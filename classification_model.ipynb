{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\honya\\Documents\\GitHub\\2024-25c-fai1-adsai-GergoHonyak242720\\Deliverables\\RealWaste\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1867 files belonging to 7 classes.\n",
      "Classes found: ['Food Organics', 'Glass', 'Metal', 'Paper_Cardboard', 'Plastic', 'Textile Trash', 'Vegetation']\n"
     ]
    }
   ],
   "source": [
    "full_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,  \n",
    "    image_size=(224, 224),  \n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "class_names = full_dataset.class_names  \n",
    "print(\"Classes found:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  \n",
    "    tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),  \n",
    "    tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),  \n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),  \n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    augmented_images = []\n",
    "    \n",
    "    augmented_images.append(data_augmentation(image))  \n",
    "    \n",
    "    augmented_images.append(tf.image.rot90(image))    \n",
    "    augmented_images.append(tf.image.rot90(augmented_images[1]))  \n",
    "    augmented_images.append(tf.image.rot90(augmented_images[2]))  \n",
    "\n",
    "    augmented_images = [tf.image.resize(img, (224, 224)) for img in augmented_images]  \n",
    "    \n",
    "    labels = [label] * len(augmented_images)\n",
    "    \n",
    "    return augmented_images, labels\n",
    "\n",
    "full_dataset = full_dataset.flat_map(\n",
    "    lambda image, label: tf.data.Dataset.from_tensor_slices(preprocess_image(image, label))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_and_labels(dataset):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for images, label in dataset:\n",
    "        data.append(images.numpy())\n",
    "        labels.append(label.numpy())\n",
    "\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "all_data, all_labels = extract_data_and_labels(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, remaining_data, train_labels, remaining_labels = train_test_split(\n",
    "    all_data, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    remaining_data, remaining_labels, test_size=0.5, random_state=42, stratify=remaining_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5974, 224, 224, 3)\n",
      "Train labels shape: (5974,)\n",
      "Validation data shape: (747, 224, 224, 3)\n",
      "Validation labels shape: (747,)\n",
      "Test data shape: (747, 224, 224, 3)\n",
      "Test labels shape: (747,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)  \n",
    "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n",
    "val_data = val_data.reshape(val_data.shape[0], -1)\n",
    "test_data = test_data.reshape(test_data.shape[0], -1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of train_data: (5974, 224, 224, 3)\n",
      "Original shape of val_data: (747, 224, 224, 3)\n",
      "Reshaped train_data: (5974, 224, 224, 3)\n",
      "Reshaped val_data: (747, 224, 224, 3)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 224, 224, 16)      448       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 224, 224, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 112, 112, 16)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 110, 110, 64)      9280      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 110, 110, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 55, 55, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 53, 53, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 53, 53, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44520391 (169.83 MB)\n",
      "Trainable params: 44519975 (169.83 MB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "print(\"Original shape of train_data:\", train_data.shape)  \n",
    "print(\"Original shape of val_data:\", val_data.shape)  \n",
    "\n",
    "train_data = train_data.reshape((train_data.shape[0], 224, 224, 3))  \n",
    "print(\"Reshaped train_data:\", train_data.shape)\n",
    "\n",
    "val_data = val_data.reshape((val_data.shape[0], 224, 224, 3))  \n",
    "print(\"Reshaped val_data:\", val_data.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, activation=\"relu\", kernel_size=3, padding=\"same\", input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization())  \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(BatchNormalization())  \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(BatchNormalization())  \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(7, activation='softmax')) \n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\honya\\anaconda3\\envs\\block_c\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\honya\\anaconda3\\envs\\block_c\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "187/187 [==============================] - ETA: 0s - loss: 3.4363 - accuracy: 0.3169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\honya\\anaconda3\\envs\\block_c\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 56s 295ms/step - loss: 3.4363 - accuracy: 0.3169 - val_loss: 1.5588 - val_accuracy: 0.4565\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 56s 300ms/step - loss: 1.7246 - accuracy: 0.3929 - val_loss: 1.3537 - val_accuracy: 0.5301\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 57s 307ms/step - loss: 1.5738 - accuracy: 0.4476 - val_loss: 1.3064 - val_accuracy: 0.5462\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 56s 298ms/step - loss: 1.4863 - accuracy: 0.4736 - val_loss: 1.3196 - val_accuracy: 0.5435\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 56s 301ms/step - loss: 1.3383 - accuracy: 0.5209 - val_loss: 1.1081 - val_accuracy: 0.6158\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 56s 298ms/step - loss: 1.2517 - accuracy: 0.5557 - val_loss: 1.1428 - val_accuracy: 0.6185\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 56s 300ms/step - loss: 1.1657 - accuracy: 0.5934 - val_loss: 1.0816 - val_accuracy: 0.6466\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 56s 297ms/step - loss: 1.0667 - accuracy: 0.6242 - val_loss: 1.1020 - val_accuracy: 0.6399\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 57s 306ms/step - loss: 0.9887 - accuracy: 0.6528 - val_loss: 0.9336 - val_accuracy: 0.6894\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 55s 297ms/step - loss: 0.8908 - accuracy: 0.6907 - val_loss: 0.9689 - val_accuracy: 0.6653\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 56s 298ms/step - loss: 0.8472 - accuracy: 0.7074 - val_loss: 1.0382 - val_accuracy: 0.6814\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 56s 299ms/step - loss: 0.8243 - accuracy: 0.7307 - val_loss: 1.0822 - val_accuracy: 0.6600\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data, train_labels_cat, \n",
    "    validation_data=(val_data, val_labels_cat),\n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels_cat)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_data)  \n",
    "y_pred_classes = np.argmax(y_pred, axis=1) \n",
    "\n",
    "y_true_classes = np.argmax(test_labels_cat, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
